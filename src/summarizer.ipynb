{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Whatstics\n",
    "\n",
    "### This script summarizes a WhatsApp chat history.\n",
    "\n",
    "<br>\n",
    "\n",
    "ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ CAUTION ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨\n",
    "\n",
    "The script use openai api and may cost you A LOT OF MONEY. Please be aware of that.\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. First configure Date limits and the paths\n",
    "\n",
    "For example:\n",
    "- START_DATE = \"2024-08-23\"\n",
    "- END_DATE = \"2024-08-23\"\n",
    "- PATH = \"../history/chat.txt\"\n",
    "- OUTPUT_PATH = \"../summary/output.txt\"\n",
    "\n",
    "Start and end date are inclusive, and must be equal\n",
    "\n",
    "ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ CAUTION ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨\n",
    "\n",
    "Bigger the date range, more expensive the cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = \"2024-08-29\"\n",
    "END_DATE = \"2024-08-29\"\n",
    "\n",
    "FILE_PATH = \"../history/conversa-ate-29.08.2024.txt\"\n",
    "SUMMARY_PATH = \"../summary\"\n",
    "\n",
    "LLM_PROVIDER = \"OPENAI\" # GOOGLE or OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ Do not change this variable! ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨\n",
    "SUMMARY_TITLE_PREFIX = \"### *Resumo do Bate-Papo do WhatsApp* - GraduaÃ§Ã£o em InteligÃªncia Artificial - \"\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "start_datetime_prompt =  datetime.strptime(START_DATE, \"%Y-%m-%d\").strftime(\"%d/%m/%Y\")\n",
    "end_datetime_prompt = datetime.strptime(END_DATE, \"%Y-%m-%d\").strftime(\"%d/%m/%Y\")\n",
    "\n",
    "print(\"Date range:\", start_datetime_prompt, end_datetime_prompt)\n",
    "\n",
    "date_range_prompt = \"\"\n",
    "if start_datetime_prompt != end_datetime_prompt:\n",
    "    date_range_prompt = f\"de {start_datetime_prompt} a {end_datetime_prompt}\"\n",
    "else:\n",
    "    date_range_prompt = f\"em {start_datetime_prompt}\"\n",
    "    \n",
    "print(\"Title:\")\n",
    "SUMMARY_TITLE = f\"{SUMMARY_TITLE_PREFIX}*{date_range_prompt}*\"\n",
    "print(SUMMARY_TITLE)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "\n",
    "def add_mesage_to_df(\n",
    "    messages, date, time, id, message, type_=\"message\", subtype=None, is_summary=False\n",
    "):\n",
    "    if is_summary:\n",
    "        print({\n",
    "            \"Date\": date,\n",
    "            \"Time\": time,\n",
    "            \"Id\": id,\n",
    "            \"Message\": message,\n",
    "            \"Type\": type_,\n",
    "            \"Action_type\": subtype,\n",
    "            \"Is_summary\": is_summary,\n",
    "        })\n",
    "    messages.append(\n",
    "        {\n",
    "            \"Date\": date,\n",
    "            \"Time\": time,\n",
    "            \"Id\": id,\n",
    "            \"Message\": message,\n",
    "            \"Type\": type_,\n",
    "            \"Action_type\": subtype,\n",
    "            \"Is_summary\": is_summary,\n",
    "        }\n",
    "    )\n",
    "    return messages\n",
    "\n",
    "\n",
    "def manage_action(messages, current_date, current_time, id, rest_of_line):\n",
    "    if \"entrou usando o link de convite deste grupo\" in rest_of_line:\n",
    "        action_type = \"entry\"\n",
    "        id = rest_of_line.split(\"entrou usando o link de convite deste grupo\")[\n",
    "            0\n",
    "        ].strip()\n",
    "    elif \"saiu\" in rest_of_line:\n",
    "        action_type = \"exit\"\n",
    "        id = rest_of_line.split(\"saiu\")[0].strip()\n",
    "    elif \"mudou a descriÃ§Ã£o do grupo\" in rest_of_line:\n",
    "        action_type = \"description_change\"\n",
    "        id = rest_of_line.split(\"mudou a descriÃ§Ã£o do grupo\")[0].strip()\n",
    "    elif \"fixou uma mensagem\" in rest_of_line:\n",
    "        action_type = \"message_pin\"\n",
    "        id = rest_of_line.split(\"fixou uma mensagem\")[0].strip()\n",
    "    elif \"mudou as configuraÃ§Ãµes\" in rest_of_line:\n",
    "        action_type = \"group_settings_change\"\n",
    "        id = rest_of_line.split(\"mudou as configuraÃ§Ãµes do grupo\")[0].strip()\n",
    "    elif \"(arquivo anexado)\" in rest_of_line:\n",
    "        action_type = \"file_attach\"\n",
    "        id = rest_of_line.split(\"(arquivo anexado)\")[0].strip()\n",
    "    elif \"criou o grupo\" in rest_of_line:\n",
    "        action_type = \"group_create\"\n",
    "        id = rest_of_line.split(\"criou o grupo\")[0].strip()\n",
    "    elif \"foi adicionado(a)\" in rest_of_line:\n",
    "        action_type = \"was_addded_by_someone\"\n",
    "        id = rest_of_line.split(\"foi adicionado(a)\")[0].strip()\n",
    "    elif \"adicionou\" in rest_of_line:\n",
    "        action_type = \"added_someone\"\n",
    "        id = rest_of_line.split(\"adicionou\")[0].strip()\n",
    "    else:\n",
    "        print(\"Error line:\", rest_of_line)\n",
    "        assert False\n",
    "\n",
    "    add_mesage_to_df(\n",
    "        messages,\n",
    "        current_date,\n",
    "        current_time,\n",
    "        id,\n",
    "        rest_of_line,\n",
    "        \"action\",\n",
    "        subtype=action_type,\n",
    "    )\n",
    "\n",
    "\n",
    "def parse_whatsapp_history(file_path):\n",
    "    # Lista para armazenar as mensagens extraÃ­das\n",
    "    messages = []\n",
    "\n",
    "    # Ler o arquivo de histÃ³rico\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        lines = file.readlines()\n",
    "\n",
    "    # Regex para identificar a data, hora e nÃºmero do remetente\n",
    "    date_and_time_pattern = re.compile(r\"(\\d{2}/\\d{2}/\\d{4}) (\\d{2}:\\d{2}) - (.*)\")\n",
    "\n",
    "    # VariÃ¡veis para acumular mensagens\n",
    "    current_date = None\n",
    "    current_time = None\n",
    "    current_id = None\n",
    "    current_message = None\n",
    "    mark_as_summary = False\n",
    "\n",
    "    for line in lines:\n",
    "        # Verifica se a linha corresponde ao padrÃ£o de uma nova mensagem\n",
    "        match = date_and_time_pattern.match(line)\n",
    "        if match:\n",
    "            if current_message:\n",
    "                messages = add_mesage_to_df(\n",
    "                    messages,\n",
    "                    current_date,\n",
    "                    current_time,\n",
    "                    current_id,\n",
    "                    current_message,\n",
    "                    is_summary=mark_as_summary,\n",
    "                )\n",
    "            current_message = \"\"\n",
    "            current_date, current_time, rest_of_line = match.groups()\n",
    "            if \"â€\" in rest_of_line:\n",
    "                manage_action(\n",
    "                    messages, current_date, current_time, current_id, rest_of_line\n",
    "                )\n",
    "            elif \":\" in rest_of_line and rest_of_line.split(\":\")[1].startswith(\n",
    "                f\" {SUMMARY_TITLE_PREFIX}\"\n",
    "            ):\n",
    "                current_id, message = rest_of_line.split(\":\", 1)\n",
    "                current_message = message.strip()\n",
    "                mark_as_summary = True\n",
    "            else:\n",
    "                if \":\" in rest_of_line:\n",
    "                    mark_as_summary = False\n",
    "                    current_id, message = rest_of_line.split(\":\", 1)\n",
    "                    current_message = message.strip()\n",
    "        else:\n",
    "            current_message += \"\\n\" + line.strip()\n",
    "\n",
    "    messages = add_mesage_to_df(\n",
    "        messages,\n",
    "        current_date,\n",
    "        current_time,\n",
    "        current_id,\n",
    "        current_message,\n",
    "        \"message\",\n",
    "        is_summary=mark_as_summary,\n",
    "    )\n",
    "\n",
    "    df = pd.DataFrame(messages)\n",
    "\n",
    "    df[\"Order\"] = range(1, len(df) + 1)\n",
    "\n",
    "    df[\"DateTime\"] = pd.to_datetime(\n",
    "        df[\"Date\"].astype(str) + \" \" + df[\"Time\"].astype(str)\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de uso\n",
    "history = parse_whatsapp_history(FILE_PATH)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history[history[\"Type\"] != \"message\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print until 100 lines each column\n",
    "pd.set_option(\"display.max_colwidth\", 112)\n",
    "history[history[\"Is_summary\"]].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Range de data para o arquivo carregado:\")\n",
    "print(\"Min DateTime:\", history[\"DateTime\"].min())\n",
    "print(\"Max DateTime:\", history[\"DateTime\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"AdiÃ§Ãµes de hoje\")\n",
    "start_datetime = datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "end_datetime = datetime.strptime(END_DATE, \"%Y-%m-%d\") + timedelta(days=1)\n",
    "\n",
    "entries = history[\n",
    "    (history[\"Action_type\"].isin([\"was_added_by_someone\", \"added_someone\", \"entry\"]))\n",
    "    & (history[\"DateTime\"] >= start_datetime)\n",
    "    & (history[\"DateTime\"] <= end_datetime)\n",
    "]\n",
    "entries[\"Id\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Convert strings to datetime objects\n",
    "start_datetime = datetime.strptime(START_DATE, \"%Y-%m-%d\")\n",
    "end_datetime = datetime.strptime(END_DATE, \"%Y-%m-%d\") + timedelta(days=1)\n",
    "\n",
    "print(start_datetime, end_datetime)\n",
    "\n",
    "messages_df = history[\n",
    "    (\n",
    "        (history[\"Type\"] == \"message\")\n",
    "        | (history[\"Action_type\"].isin([\"was_added_by_someone\", \"added_someone\", \"entry\"]))\n",
    "    )\n",
    "    & (history[\"DateTime\"] >= start_datetime)\n",
    "    & (history[\"DateTime\"] < end_datetime)\n",
    "    & (~history[\"Is_summary\"])\n",
    "]\n",
    "messages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_df[messages_df[\"Type\"] != \"message\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Range de data para os dados do resumo:\")\n",
    "print(\"Min DateTime:\", messages_df[\"DateTime\"].min())\n",
    "print(\"Max DateTime:\", messages_df[\"DateTime\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "# Full chat string\n",
    "# Every new message starts with a new line followed by NM:\n",
    "full_chat_str = \" \".join(messages_df[\"Message\"].values)\n",
    "\n",
    "pprint(full_chat_str[100:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pprint import pprint\n",
    "\n",
    "RANKING_PROMPT = \"\"\"\n",
    "Analise as mensagens do grupo de WhataApp do curso de GraduaÃ§Ã£o em InteligÃªncia Artificial. \n",
    "Classifique os assuntos discutidos com base na relevÃ¢ncia para a turma.\n",
    "Considere a importÃ¢ncia das informaÃ§Ãµes compartilhadas, a frequÃªncia com que foram discutidas e a quantidade de interaÃ§Ãµes que geraram.\n",
    "InformaÃ§Ãµes consideradas importantes podem incluir:\n",
    "    - contatos (LinkedIn, redes sociais, emails e telefones);\n",
    "    - novos membros\n",
    "    - recursos educacionais (links, playlists do youtube e outros, livros, cursos etc);\n",
    "    - indicaÃ§Ã£o de softwares;\n",
    "    - notas de aula;\n",
    "    - vagas de emprego;\n",
    "    - recomendaÃ§Ãµes de empresas ou de serviÃ§os especÃ­ficos;\n",
    "    - informaÃ§Ãµes acadÃªmicas (eventos, datas, prazos, trabalhos, atividades);\n",
    "    - quaisquer outros tÃ³picos que sejam relevantes.\n",
    "Por favor, retorne apenas uma lista com um tÃ­tulo para as categorias mais relevantes (mÃ¡ximo de 6 categorias), sem nenhuma informaÃ§Ã£o adicional.\n",
    "\"\"\"\n",
    "\n",
    "NEWSLETTER_PROMPT = f\"\"\"Por favor, forneÃ§a um parÃ¡grafo para abrir uma newsletter cobrindo os seguintes tÃ³picos:\"\"\"\n",
    "\n",
    "pprint(RANKING_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model(model):\n",
    "    print(\"Uging model: \")\n",
    "    print(model.dict())\n",
    "    print('\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "if LLM_PROVIDER == \"GOOGLE\":\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", max_tokens=2500)\n",
    "    model_name = \"gemini-1.5-pro\"\n",
    "elif LLM_PROVIDER == \"OPENAI\":\n",
    "    llm = ChatOpenAI(model=\"gpt-4o-mini\", max_tokens=2500)\n",
    "    model_name = \"gpt-4o-mini\"\n",
    "else:\n",
    "    raise ValueError(\"Invalid LLM_PROVIDER value\")\n",
    "\n",
    "print_model(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ranking_prompt = PromptTemplate(\n",
    "    template=\"{instruction}\\nAs mensagens: ```\\{messages}```\",\n",
    "    input_variables=[\"instruction\", \"messages\"],\n",
    ")\n",
    "\n",
    "ranking_chain = ranking_prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "langchain.debug = False\n",
    "\n",
    "ranking_response = ranking_chain.invoke(\n",
    "    {\n",
    "        \"instruction\": RANKING_PROMPT,\n",
    "        \"messages\": full_chat_str,\n",
    "    }\n",
    ")\n",
    "\n",
    "pprint(ranking_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY_PROMPT = \"\"\"\n",
    "# VocÃª receberÃ¡ um histÃ³rico de conversas do WhatsApp. Para cada um dos seguintes tÃ³picos: \"{topics}\", analise as mensagens e\n",
    "# faÃ§a um resumo em subtÃ³picos do que discutido. Mostre todos os links que foram compartilhados sobre cada tÃ³pico.\n",
    "# \"\"\"\n",
    "\n",
    "SUMMARY_PROMPT = (\n",
    "    \"VocÃª receberÃ¡ um histÃ³rico de conversas do WhatsApp. Para cada um dos \"\n",
    "    'seguintes tÃ³picos: \"{topics}\", '\n",
    "    \"analise as mensagens e faÃ§a um resumo em subtÃ³picos do que foi discutido. \"\n",
    "    \"Para cada subtÃ³pico, liste **todos** os links compartilhados explicitamente, sem omitir nenhum. \"\n",
    "    \"Se houver links adicionais que nÃ£o estejam claramente associados a nenhum dos tÃ³picos listados, \"\n",
    "    'crie uma categoria \"Outros links\" e inclua-os lÃ¡. Seja minucioso na listagem de links para garantir '\n",
    "    \"que nenhum seja deixado de fora. \"\n",
    "    \"NÃ£o incluir tÃ­tulo, inicie pelos tÃ³picos. \"\n",
    "    \"Cite os contatos de todos os novos membros, sem destacar nenhum deles. \"\n",
    ")\n",
    "\n",
    "summary_instruction = SUMMARY_PROMPT.format(\n",
    "    topics=ranking_response, SUMMARY_TITLE=SUMMARY_TITLE\n",
    ")\n",
    "pprint(summary_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "summary_prompt = PromptTemplate(\n",
    "    template=\"{instruction}\\nAs mensagens: ```\\{messages}```\",\n",
    "    input_variables=[\"instruction\", \"messages\"],\n",
    ")\n",
    "\n",
    "summary_chain = ranking_prompt | llm\n",
    "\n",
    "langchain.debug = False\n",
    "\n",
    "summary_response = summary_chain.invoke({\n",
    "    \"instruction\": summary_instruction,\n",
    "    \"messages\": full_chat_str,\n",
    "})\n",
    "\n",
    "pprint(summary_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_response.usage_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cost(input_tokens: int, output_tokens: int, llm_model: str):\n",
    "    # Dollar costs above 128k tokens\n",
    "    dollar_dict = {\n",
    "        \"gpt-4o-mini\": {\n",
    "            \"input_cost_1M_tokens\": 0.15,\n",
    "            \"output_cost_1M_tokens\": 0.6,\n",
    "        },\n",
    "        \"gemini-1.5-pro\": {\n",
    "            \"input_cost_1M_tokens\": 0.075,\n",
    "            \"output_cost_1M_tokens\": 0.3,\n",
    "        },\n",
    "    }\n",
    "\n",
    "    input_cost = dollar_dict[llm_model][\"input_cost_1M_tokens\"]\n",
    "    output_cost = dollar_dict[llm_model][\"output_cost_1M_tokens\"]\n",
    "    total_cost = input_cost * input_tokens / 1e6 + output_cost * output_tokens / 1e6\n",
    "    print(\"Custo total em dÃ³lares:\", total_cost)\n",
    "    return total_cost\n",
    "\n",
    "dollars = calculate_cost(\n",
    "    summary_response.usage_metadata[\"input_tokens\"],\n",
    "    summary_response.usage_metadata[\"output_tokens\"],\n",
    "    model_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_to_save = (\n",
    "    SUMMARY_TITLE\n",
    "    + \"\\n\\nGerado pelo [**Whatstics**](**https://github.com/brunoconterato/Whatstics**). Contribua!\\n\\n\"\n",
    "    + f\"Modelo gerador: {model_name}\\n\\n\"\n",
    "    + summary_response.content\n",
    ")\n",
    "pprint(summary_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy to clipboard:\n",
    "import pyperclip\n",
    "pyperclip.copy(summary_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_range = datetime.strptime(START_DATE, \"%Y-%m-%d\").strftime(\"%d-%m-%Y\")\n",
    "end_range = datetime.strptime(END_DATE, \"%Y-%m-%d\").strftime(\"%d-%m-%Y\")\n",
    "\n",
    "if start_range == end_range:\n",
    "    date_range_filename = f\"summary_whatsapp_on_{start_range}\"\n",
    "else:\n",
    "    date_range_filename = f\"summary_whatsapp_from_{start_range}_to_{end_range}\"\n",
    "\n",
    "llm_filename = f\"_{LLM_PROVIDER}\".lower()\n",
    "extension = \".txt\"\n",
    "\n",
    "filepath = f\"{SUMMARY_PATH}/{date_range_filename}{llm_filename}{extension}\"\n",
    "\n",
    "# save to file\n",
    "with open(filepath, \"w\") as file:\n",
    "    file.write(summary_to_save)\n",
    "    print(f\"Saved summary to: {filepath}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨ Chain multipla! ğŸš¨ğŸš¨ğŸš¨ğŸš¨ğŸš¨\n",
    "# ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ Apenas aprendizado! O script vai rodar separado mesmo ğŸš€ğŸš€ğŸš€ğŸš€ğŸš€ \n",
    "\n",
    "# from operator import itemgetter\n",
    "\n",
    "# from langchain_core.output_parsers import StrOutputParser\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# ranking_prompt = PromptTemplate(\n",
    "#     template=\"{instruction}\\nAs mensagens: ```\\{messages}```\",\n",
    "#     input_variables=[\"instruction\", \"messages\"],\n",
    "# )\n",
    "# summary_prompt = PromptTemplate(\n",
    "#     template=SUMMARY_PROMPT,\n",
    "#     input_variables=[\"topics\", \"SUMMARY_TITLE\"]\n",
    "# )\n",
    "\n",
    "# model = ChatOpenAI()\n",
    "\n",
    "# ranking_chain = ranking_prompt | model | StrOutputParser()\n",
    "\n",
    "# summary_chain = (\n",
    "#     # A variÃ¡vel \"topics\" Ã© exatamente a saÃ­da do ranking_chain\n",
    "#     {\"topics\": ranking_chain, \"SUMMARY_TITLE\": itemgetter(\"SUMMARY_TITLE\")}\n",
    "#     # Entradas do summary_prompt: input_variables=[\"topics\", \"SUMMARY_TITLE\"]\n",
    "#     | summary_prompt\n",
    "#     | model\n",
    "#     | StrOutputParser()\n",
    "# )\n",
    "# langchain.debug = False\n",
    "\n",
    "# summary_chain.invoke(\n",
    "#     {\n",
    "#         \"instruction\": RANKING_PROMPT,\n",
    "#         \"messages\": full_chat_str,\n",
    "#         \"SUMMARY_TITLE\": SUMMARY_TITLE,\n",
    "#     }\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
